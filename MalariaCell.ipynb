{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Deep Neural Networks are trained to output predictions as needed based on the input. The convolutional neural networks are a type of deep neural networks used to analyze visual imagery. The convolutional neural networks takes an image as the imnput and outputs the predictions based on the data that it has been trained with. \n",
    "\n",
    "They are composed of multiple hidden layers between the input and the output layer. The hidden layers in a convolutional neural network typically consists of convolutional layers, activation layers and pooling layers. Each layer in a Convolutional Neural Network is associated with learning to recognize a particular feature in the given image. The first few layers are associated with learning to recognize basic features such as corners and edges, the next layers are associated with recognizing features such as color transitions, the other layers learn to recognize basic objects in the image. The outputs from these layers are then flattened and input into a fully connected neural network with an output layer. The output layer can have an activation function based on the output that is required. The activations can either be sigmoid, softmax, ReLU or tanh. \n",
    "\n",
    "![CNN Overview](https://cdn-images-1.medium.com/max/2400/1*vkQ0hXDaQv57sALXAJquxA.jpeg)\n",
    "\n",
    "\n",
    "## Different types of layers of in Convolutional Neural Network \n",
    "\n",
    "There are various architectures available for convolutional neural networks such as LeNet, GoogleLeNet/Inception, ResNet, AlexNet, etc. These networks are built up of multiple, different types of layers such as convolutional layers, activation layers and pooling layers. Each type of layer performs a different operation.\n",
    "\n",
    "### A. Convolution layer\n",
    "A kernel in this layer performs a convolution operation on the input image. The kernel will be of the specified width and height and will scan through the given image in a linear order with the specified strides. Strides are the jumps given to a kernel window over the image. The size of each kernel should be either less than or equal to the input image. The convolution operation involves multiplication of the weights of the kernel with the corresponding pixel values of the image over with a particular pixel of the kernel coincides, and then adding up of the resultant values into a single value and storing it in a cell of the matrix. Then, the kernel will be moved over the image by the corresponding stride and the multiplication and addition operation will be performed on that part of the image and the result will be stored in the new cell of the resultant matrix. There can be multiple number of kernels for the given layer of the convolutional nerual network and the resultant matrices will be cascaded to form the output. The output will be added with a bias and passed through an activation layer to form the new output layer. \n",
    "\n",
    "![Convolution Operation](https://cdn-images-1.medium.com/max/1600/1*7S266Kq-UCExS25iX_I_AQ.png)\n",
    "\n",
    "### B. Activation layer in CNN and activation functions of Deep Neural Networks\n",
    "The resultant values from the convolution layer will be passed into an activation layer. The activation layer will contain an activation function such as ReLU, sigmoid or tanh. These functions take in the values given by the convolution operation and will standardize the values. \n",
    "\n",
    "1. __ReLU__ <br>\n",
    "The rectified linear unit function is used the most as the activation function of the activation layer in the convolutional nerual network. This function outputs a linear value between 0 and infinity, based on the input. This function is also used as an activation function for regression problems.\n",
    "![ReLU](https://cdn-images-1.medium.com/max/1600/1*DfMRHwxY1gyyDmrIAd-gjQ.png)\n",
    "\n",
    "2. __Sigmoid__ <br>\n",
    "The sigmoid activation function outputs either 0 or 1 based on the input. This is used as an activation function for classification problems. \n",
    "![Sigmoid Function](https://cdn-images-1.medium.com/max/1600/1*Xu7B5y9gp0iL5ooBj7LtWw.png)\n",
    "\n",
    "3. __tanh__ <br>\n",
    "This function outputs a value between -1 and 1 based on the input. This activation function is mostly used to build LSTMs. \n",
    "![tanh Function](http://mathworld.wolfram.com/images/interactive/TanhReal.gif)\n",
    "\n",
    "4. __Softmax__ <br>\n",
    "This function contains multiple hidden units that gets activated based on the predicted probability of the output belonging to a particular class. This function can be used as an activation function for the output layer in multiclass classification problems. The hidden units output a value between 0 to 1 based on the predicted probability of the input belonging to a particular class.\n",
    "![Softmax Function](https://developers.google.com/machine-learning/crash-course/images/SoftmaxLayer.svg)\n",
    "\n",
    "### C. Pooling Layer\n",
    "Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters of one layer into a single neuron in the next layer. The pooling operation uses a pooling kernel of a specified width and height that moves over the neurons of a layer and outputs the maximum, minimum or the average of all the values that comes under that kernel. \n",
    "<br>\n",
    "<br>\n",
    "For Example:\n",
    "![Example of Max Pooling](http://cs231n.github.io/assets/cnn/maxpool.jpeg)\n",
    "This example uses a pooling kernel of size 2x2. This kernel moves over the previous layer and outputs the maximum of all the values in the area that it moves over.\n",
    "\n",
    "### D. Fully Connected Layers\n",
    "The convolutional neural networks extracts the features from the image provided. These outputs are flattened and provided to the fully connected deep neural network layers that connect to the output layer to output the further predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malaria Detection using cell images\n",
    "\n",
    "This is a solution for the kaggle compitition (Link: https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria) using convolutional neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape = (50, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infected = os.listdir('../data/cell_images/Parasitized')\n",
    "uninfected = os.listdir('../data/cell_images/Uninfected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in infected:\n",
    "    try:\n",
    "        img = cv2.imread('..\\\\data\\\\cell_images\\\\Parasitized\\\\'+i, cv2.IMREAD_COLOR)\n",
    "        imArr = Image.fromarray(img, 'RGB')\n",
    "        imArr = imArr.resize((50, 50))\n",
    "        imArr_1 = imArr.rotate(45)\n",
    "        imArr_2 = imArr.rotate(75)\n",
    "        imArr_3 = cv2.blur(np.array(imArr), (5, 5))\n",
    "    \n",
    "        images.append(np.array(imArr))\n",
    "        images.append(np.array(imArr_1))\n",
    "        images.append(np.array(imArr_2))\n",
    "        images.append(np.array(imArr_3))\n",
    "    \n",
    "        for i in range(0, 4):\n",
    "            labels.append(1)\n",
    "    \n",
    "    except:\n",
    "        print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55116"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55116"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in uninfected:\n",
    "    try:\n",
    "        img = cv2.imread('..\\\\data\\\\cell_images\\\\Uninfected\\\\'+i, cv2.IMREAD_COLOR)\n",
    "        imArr = Image.fromarray(img, 'RGB')\n",
    "        imArr = imArr.resize((50, 50))\n",
    "        imArr_1 = imArr.rotate(45)\n",
    "        imArr_2 = imArr.rotate(75)\n",
    "        imArr_3 = cv2.blur(np.array(imArr), (5, 5))\n",
    "    \n",
    "        images.append(np.array(imArr))\n",
    "        images.append(np.array(imArr_1))\n",
    "        images.append(np.array(imArr_2))\n",
    "        images.append(np.array(imArr_3))\n",
    "    \n",
    "        for i in range(0, 4):\n",
    "            labels.append(0)\n",
    "    \n",
    "    except:\n",
    "        print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110232"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110232"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set images length: 93697\n",
      "Training set labels length: 93697\n",
      "Test set images length: 16535\n",
      "Test set labels length: 16535\n"
     ]
    }
   ],
   "source": [
    "print('Training set images length: '+str(len(X_train)))\n",
    "print('Training set labels length: '+str(len(y_train)))\n",
    "print('Test set images length: '+str(len(X_test)))\n",
    "print('Test set labels length: '+str(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93697, 50, 50, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93697,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (28, 28), strides=1, input_shape=X_train.shape[1:], activation=tf.nn.relu, padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (13, 13), strides=1, activation=tf.nn.relu, padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(6, 6),strides=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=tf.nn.relu))\n",
    "model.add(Dense(1, activation=tf.nn.sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 23, 23, 16)        37648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 23, 23, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 16)        43280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 11, 11, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 229,025\n",
      "Trainable params: 228,961\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "93697/93697 [==============================] - 723s 8ms/sample - loss: 0.1844 - acc: 0.7308\n",
      "Epoch 2/5\n",
      "93697/93697 [==============================] - 714s 8ms/sample - loss: 0.1174 - acc: 0.8346\n",
      "Epoch 3/5\n",
      "93697/93697 [==============================] - 734s 8ms/sample - loss: 0.0688 - acc: 0.9075\n",
      "Epoch 4/5\n",
      "93697/93697 [==============================] - 717s 8ms/sample - loss: 0.0569 - acc: 0.9247\n",
      "Epoch 5/5\n",
      "93697/93697 [==============================] - 726s 8ms/sample - loss: 0.0512 - acc: 0.9327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a74ce5a198>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16535/16535 [==============================] - 51s 3ms/sample - loss: 0.0607 - acc: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06068292592168035, 0.9212579]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
